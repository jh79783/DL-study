# LeNet

LeNet은 Yann Lecun 의 "Gradient-based learning applied to document recognition" 논문에서 제시한 모델로 손글씨를 인식하는 문제를 해결하는데 사용되었다.



## 구조

![LeNet](..\img\LeNet.jpg)

위의 그림은 LeNet-5를 나타낸 것이다.
구조는 input, 3개의 convolution Layer, 2개의 subsampling layer, 1개의 fully-connected-layer, output으로 구성되어 classfication을 수행하는 구조이다. 
C1 부터 F6까지 사용한 활성화 함수는 tanh이다.
5\*5의 filter에 bias가 더해져 feature map을 만들게 된다. 또한, 패딩처리를 해주지 않아 feture map의 사이즈가 줄기도 한다.
subsampling layer에서 Average pooling을 하고 (2\*2)크기의 filter를 사용, stride는 2를 사용한다.

|            | shape      | filter_shape | parameter                  | feature map | sum                                | product                          |
| ---------- | ---------- | ------------ | -------------------------- | ----------- | ---------------------------------- | -------------------------------- |
| input      | (32*32\*1) |              |                            |             |                                    |                                  |
| C1 layer   |            | (5\*5\*1)    | (5\*5\*1+1)\*6 = 156       | (28\*28\*6) | (5\*5\*1)\*(28\*28\*6-1) = 117,575 | (5\*5\*1)\*(28\*28\*6) = 117,600 |
| S2 layer   |            | (2\*2)       | (1+1)\*6 = 12              | (14\*14\*6) |                                    |                                  |
| C3_1 layer |            | (5\*5\*3)    | (5\*5\*3+1)\*6 = 456       | (10\*10\*6) | (5\*5\*3)\*(10\*10\*6-1) = 44,925  | (5\*5\*3)\*(10\*10\*6) = 45,000  |
| C3_2 layer |            | (5\*5\*4)    | (5\*5\*4+1)\*6 = 606       | (10\*10\*6) | (5\*5\*4)\*(10\*10\*6-1) = 59,900  | (5\*5\*4)\*(10\*10\*6) = 60,000  |
| C3_3 layer |            | (5\*5\*4)    | (5\*5\*4+1)\*3 = 303       | (10\*10\*3) | (5\*5\*4)\*(10\*10\*3-1) = 29,900  | (5\*5\*4)\*(10\*10\*3) = 30,000  |
| C3_4 layer |            | (5\*5\*6)    | (5\*5\*6+1)\*1 = 151       | (10\*10\*1) | (5\*5\*6)\*(10\*10\*1-1) = 14,850  | (5\*5\*6)\*(10\*10\*1) = 15,000  |
| S4 layer   |            | (2\*2)       | (1+1)\*16 = 32             | (5\*5\*16)  |                                    |                                  |
| C5_layer   |            | (5\*5\*16)   | (5\*5\*16+1)\*120 = 48,120 | (1\*1\*120) | (5\*5\*16)\*(1\*1\*120-1) = 47,600 | (5\*5\*16)\*(1\*1\*120) = 48,000 |
| F6 layer   |            |              | (120+1)\*84 = 10,164       |             |                                    |                                  |
| total      |            |              | 60,000                     |             | 314,750                            | 315,600                          |

평균풀링인데 파라미터가 필요하다. 논문에 의하면 평균을 낸 후에 한 개의 가중치를 곱해주고 바이어스를 더해준다고 한다. 이 값들은 시그모이드 함수를 통해 활성화가 된다.